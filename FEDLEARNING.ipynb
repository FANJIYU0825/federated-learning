{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FEDLEARNING.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAIXZGbWxCjwItkRZmlae1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FANJIYU0825/federated-learning/blob/master/FEDLEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flWbZZ91-lqJ"
      },
      "source": [
        "我這邊是clone\n",
        "有專門為  colab 做參數的微調"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgwvxM1VuSok"
      },
      "source": [
        "Hint:這些東西都是其實在opt內部都有但是因為要符合環境需要所以我會特別拿出來調教\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8aln5s1aG2h"
      },
      "source": [
        "!git clone 'https://github.com/FANJIYU0825/federated-learning.git'\n",
        "#Here I use the colab to print \n",
        "#If you need to add customize mmodel you need to use the \n",
        "#append\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/federated-learning/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv_BFNFelKKi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kad2E6VOaV3k"
      },
      "source": [
        "import matplotlib\n",
        "#把fig儲存下來 \n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "# data set I want \n",
        "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
        "# 我把參數稍作做出調整RR\n",
        "# 因為這邊會需要colab 上運行需要加入\n",
        "from utils.options import args_parser\n",
        "from models.Update import LocalUpdate\n",
        "# data set I want \n",
        "from models.Nets import MLP, CNNMnist, CNNCifar\n",
        "# algorithm We want to use here \n",
        "from models.Fed import FedAvg\n",
        "\n",
        "from models.test import test_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qn1MJ9T5JQY"
      },
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "def args_parser():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # federated arguments\n",
        "    parser.add_argument('--epochs', type=int, default=10, help=\"rounds of training\")\n",
        "    parser.add_argument('--num_users', type=int, default=100, help=\"number of users: K\")\n",
        "    parser.add_argument('--frac', type=float, default=0.1, help=\"the fraction of clients: C\")\n",
        "    parser.add_argument('--local_ep', type=int, default=5, help=\"the number of local epochs: E\")\n",
        "    parser.add_argument('--local_bs', type=int, default=10, help=\"local batch size: B\")\n",
        "    parser.add_argument('--bs', type=int, default=128, help=\"test batch size\")\n",
        "    parser.add_argument('--lr', type=float, default=0.01, help=\"learning rate\")\n",
        "    parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
        "    parser.add_argument('--split', type=str, default='user', help=\"train-test split type, user or sample\")\n",
        "\n",
        "    # model arguments\n",
        "    parser.add_argument('--model', type=str, default='mlp', help='model name')\n",
        "    parser.add_argument('--kernel_num', type=int, default=9, help='number of each kind of kernel')\n",
        "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
        "                        help='comma-separated kernel size to use for convolution')\n",
        "    parser.add_argument('--norm', type=str, default='batch_norm', help=\"batch_norm, layer_norm, or None\")\n",
        "    parser.add_argument('--num_filters', type=int, default=32, help=\"number of filters for conv nets\")\n",
        "    parser.add_argument('--max_pool', type=str, default='True',\n",
        "                        help=\"Whether use max pooling rather than strided convolutions\")\n",
        "\n",
        "    # other arguments\n",
        "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name of dataset\")\n",
        "    parser.add_argument('--iid', action='store_true', help='whether i.i.d or not')\n",
        "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
        "    parser.add_argument('--num_channels', type=int, default=3, help=\"number of channels of imges\")\n",
        "    parser.add_argument('--tpu', type=int, default=0, help=\"GPU ID, -1 for CPU\")\n",
        "    parser.add_argument('--stopping_rounds', type=int, default=10, help='rounds of early stopping')\n",
        "    parser.add_argument('--verbose', action='store_true', help='verbose print')\n",
        "    parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
        "    parser.add_argument('--all_clients', action='store_true', help='aggregation over all clients')\n",
        "    #這邊告訴我們如去設定參數\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTNLAYgf7GDs"
      },
      "source": [
        "args = args_parser()\n",
        "args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o73eOo_d-hc"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # parse args\n",
        "    args = args_parser()\n",
        "    #使用資源調用\n",
        "    args.device = torch.device('cuda:{}'.format(args.tpu) if torch.cuda.is_available() and args.tpu != -1 else 'cpu')\n",
        "\n",
        "    # load dataset and split users\n",
        "    if args.dataset == 'mnist':\n",
        "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
        "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
        "        # sample users\n",
        "        if args.iid:\n",
        "            dict_users = mnist_iid(dataset_train, args.num_users)\n",
        "        else:\n",
        "            dict_users = mnist_noniid(dataset_train, args.num_users)\n",
        "    elif args.dataset == 'cifar':\n",
        "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
        "        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
        "        if args.iid:\n",
        "            dict_users = cifar_iid(dataset_train, args.num_users)\n",
        "        else:\n",
        "            exit('Error: only consider IID setting in CIFAR10')\n",
        "    else:\n",
        "        exit('Error: unrecognized dataset')\n",
        "    img_size = dataset_train[0][0].shape\n",
        "\n",
        "    # build model\n",
        "    if args.model == 'cnn' and args.dataset == 'cifar':\n",
        "        net_glob = CNNCifar(args=args).to(args.device)\n",
        "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
        "        net_glob = CNNMnist(args=args).to(args.device)\n",
        "    elif args.model == 'mlp':\n",
        "        len_in = 1\n",
        "        for x in img_size:\n",
        "            len_in *= x\n",
        "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
        "    else:\n",
        "        exit('Error: unrecognized model')\n",
        "    print(net_glob)\n",
        "    net_glob.train()\n",
        "\n",
        "    # copy weights\n",
        "    w_glob = net_glob.state_dict()\n",
        "\n",
        "    # training\n",
        "    loss_train = []\n",
        "    cv_loss, cv_acc = [], []\n",
        "    val_loss_pre, counter = 0, 0\n",
        "    net_best = None\n",
        "    best_loss = None\n",
        "    val_acc_list, net_list = [], []\n",
        "\n",
        "    if args.all_clients: \n",
        "        print(\"Aggregation over all clients\")\n",
        "        w_locals = [w_glob for i in range(args.num_users)]\n",
        "    for iter in range(args.epochs):\n",
        "        loss_locals = []\n",
        "        if not args.all_clients:\n",
        "            w_locals = []\n",
        "        m = max(int(args.frac * args.num_users), 1)\n",
        "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
        "        for idx in idxs_users:\n",
        "            local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
        "            w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
        "            if args.all_clients:\n",
        "                w_locals[idx] = copy.deepcopy(w)\n",
        "            else:\n",
        "                w_locals.append(copy.deepcopy(w))\n",
        "            loss_locals.append(copy.deepcopy(loss))\n",
        "        # update global weights\n",
        "        w_glob = FedAvg(w_locals)\n",
        "\n",
        "        # copy weight to net_glob\n",
        "        net_glob.load_state_dict(w_glob)\n",
        "\n",
        "        # print loss\n",
        "        loss_avg = sum(loss_locals) / len(loss_locals)\n",
        "        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
        "        loss_train.append(loss_avg)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ckz61-X9xX9"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def test_img(net_g, datatest, args):\n",
        "    net_g.eval()\n",
        "    # testing\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    data_loader = DataLoader(datatest, batch_size=args.bs)\n",
        "    l = len(data_loader)\n",
        "    for idx, (data, target) in enumerate(data_loader):\n",
        "        if args.tpu != -1:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        log_probs = net_g(data)\n",
        "        # sum up batch loss\n",
        "        # 這邊需要去調整你所使用的參數\n",
        "        test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
        "        # get the index of the max log-probability\n",
        "        y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
        "        correct += y_pred.eq(target.data.view_as(y_pred)).long().tpu().sum()\n",
        "\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    accuracy = 100.00 * correct / len(data_loader.dataset)\n",
        "    if args.verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f} \\nAccuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(data_loader.dataset), accuracy))\n",
        "    return accuracy, test_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwJVoh7o9w_t"
      },
      "source": [
        "訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kgo1O9v5qbJ"
      },
      "source": [
        "     # plot loss curve\n",
        "plt.figure()\n",
        "plt.plot(range(len(loss_train)), loss_train)\n",
        "plt.ylabel('train_loss')\n",
        "net_glob.eval()\n",
        "acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
        "acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
        "print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
        "print(\"Testing accuracy: {:.2f}\".format(acc_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDIeh7Dt3cr"
      },
      "source": [
        "![](https://i.imgur.com/Mp08j2a.jpg)\n"
      ]
    }
  ]
}